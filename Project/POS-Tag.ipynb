{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "# from crfseg import CRF\n",
    "import torch.nn.functional as F\n",
    "import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "# Function to extract noun phrases from POS tags\n",
    "# def extract_noun_phrases(pos_tags):\n",
    "#     # Define patterns for noun phrases\n",
    "#     patterns = [\n",
    "#         [['NN'], ['NNS'], ['NNP'], ['NNPS']],\n",
    "#         [['DT', 'NN'], ['DT', 'NNS'], ['DT', 'NNP'], ['DT', 'NNPS'], ['JJ', 'NN'], ['JJ', 'NNS'], ['JJ', 'NNP'], ['JJ', 'NNPS']],\n",
    "#         [['DT', 'JJ', 'NN'], ['DT', 'JJ', 'NNS'], ['DT', 'JJ', 'NNP'], ['DT', 'JJ', 'NNPS']],\n",
    "#     ]\n",
    "\n",
    "#     noun_phrases = []\n",
    "\n",
    "#     # Iterate through the POS tags\n",
    "#     for i in range(len(pos_tags)):\n",
    "#         # Initialize flag to check if a longer keyword is found\n",
    "#         longer_keyword_found = False\n",
    "\n",
    "#         # Iterate through all possible lengths (up to trigrams)\n",
    "#         for length in range(3, 0, -1):  # Start from length 3 and move to length 1\n",
    "#             if i + length <= len(pos_tags):\n",
    "#                 current_sequence = [tag for word, tag in pos_tags[i:i+length]]\n",
    "#                 current_keyword = ' '.join(word for word, tag in pos_tags[i:i+length])\n",
    "\n",
    "#                 # Check if current sequence matches any pattern\n",
    "#                 for pattern in patterns[length - 1]:  # Adjust index for patterns\n",
    "#                     if current_sequence == pattern:\n",
    "#                         noun_phrases.append(current_keyword)\n",
    "#                         # longer_keyword_found = True\n",
    "#                         # break\n",
    "\n",
    "#                 # if longer_keyword_found:\n",
    "#                 #     break  # Break loop if a longer keyword is found\n",
    "    \n",
    "#     # Sort noun phrases based on their length in reverse order\n",
    "#     noun_phrases.sort(key=len, reverse=True)\n",
    "#     return noun_phrases\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_noun_phrases(pos_tags):\n",
    "    # Define patterns for noun phrases\n",
    "    patterns = [\n",
    "        r'NN.?',\n",
    "        r'DT NN.?',\n",
    "        r'JJ NN.?',\n",
    "        r'DT JJ NN.?',\n",
    "        r'NN.? IN NN.?',\n",
    "        r'NN.? VB.? NN.?',\n",
    "        r'NN.? VBP NN.?|NN.? VBP NNS.?|NNS.? VBP NN.?|NNS.? VBP NNS.?'\n",
    "    ]\n",
    "\n",
    "    noun_phrases = []\n",
    "\n",
    "    # Convert the list of tuples to a space-separated string\n",
    "    pos_string = ' '.join(tag for word, tag in pos_tags)\n",
    "\n",
    "    # Check if the POS string matches any pattern\n",
    "    for pattern in patterns:\n",
    "        for match in re.finditer(pattern, pos_string):\n",
    "            # Get the start and end indices of the match\n",
    "            start, end = match.span()\n",
    "\n",
    "            # Convert the indices to word indices\n",
    "            start = pos_string[:start].count(' ')\n",
    "            end = pos_string[:end].count(' ')\n",
    "\n",
    "            # Extract the corresponding words\n",
    "            noun_phrase = ' '.join(word for word, tag in pos_tags[start:end])\n",
    "            \n",
    "            # Check if the noun phrase is not empty\n",
    "            if noun_phrase.strip():\n",
    "                noun_phrases.append(noun_phrase)\n",
    "\n",
    "    # Remove empty strings from the list\n",
    "    noun_phrases = [phrase for phrase in noun_phrases if phrase]\n",
    "\n",
    "    return noun_phrases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "        # iterate through the files in the data directory\n",
    "        self.txtfiles = []\n",
    "        self.annfiles = []\n",
    "\n",
    "        for file in os.listdir(data_dir):\n",
    "            if file.endswith(\".txt\"):\n",
    "                self.txtfiles.append(file)\n",
    "        \n",
    "        self.tokeniser = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    def tokenise(self , text):\n",
    "        tokens = []  # List to store tokens\n",
    "        starting_offsets = []  # List to store starting offsets\n",
    "        current_token = ''  # Variable to store current token\n",
    "        offset = 0  # Starting offset\n",
    "\n",
    "        for char in text:\n",
    "            if char == ' ':\n",
    "                if current_token:  # If token is not empty\n",
    "                    tokens.append(current_token.lower())  # Append token in lowercase\n",
    "                    starting_offsets.append(offset - len(current_token))  # Store starting offset\n",
    "                    current_token = ''  # Reset current token\n",
    "                offset += 1  # Move offset to next character\n",
    "            else:\n",
    "                current_token += char  # Append character to current token\n",
    "                offset += 1  # Move offset to next character\n",
    "\n",
    "        # Handling the last token if it exists after the loop ends\n",
    "        if current_token:\n",
    "            tokens.append(current_token.lower())  # Append token in lowercase\n",
    "            starting_offsets.append(offset - len(current_token))  # Store starting offset\n",
    "\n",
    "        return starting_offsets , tokens\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.txtfiles)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        txtfile = self.txtfiles[index]\n",
    "        sampleid = txtfile.split(\".\")[0]\n",
    "        \n",
    "        # read the text file\n",
    "        with open(os.path.join(self.data_dir, txtfile), 'r') as file:\n",
    "            txt = file.read()\n",
    "        \n",
    "        # read the annotation file\n",
    "        annfilename = sampleid + \".ann\"\n",
    "        with open(os.path.join(self.data_dir, annfilename), 'r') as file:\n",
    "            ann = file.read()\n",
    "        \n",
    "        offsets , tokenisedtxt = self.tokenise(txt)\n",
    "        tagslist = np.zeros(len(tokenisedtxt))\n",
    "        # now iterate through the ann file , in each line , divide into spaces and get the last word \n",
    "        # make tagslist[i] = 1 if the word is in the tokenisedtxt\n",
    "        for line in ann.split('\\n'):\n",
    "            if line == '':\n",
    "                continue\n",
    "            words = line.split()\n",
    "            if words[0][0] != 'T':\n",
    "                continue\n",
    "\n",
    "            ssofset = words[2]\n",
    "            endoffset = words[3]\n",
    "\n",
    "            # add a 1 to each index of tagslist for indexes where offset is between ssofset and endoffset (including both)\n",
    "            for i in range(len(offsets)):\n",
    "                if offsets[i] >= int(ssofset) and offsets[i] <= int(endoffset):\n",
    "                    tagslist[i] = 1\n",
    "        \n",
    "        # Convert tokens to IDs using BERT tokenizer\n",
    "        tokenisedids = self.tokeniser.convert_tokens_to_ids(tokenisedtxt)\n",
    "        \n",
    "        # Perform POS tagging\n",
    "        pos_tags = nltk.pos_tag(tokenisedtxt)\n",
    "        \n",
    "        # Extract noun phrases from POS tags\n",
    "        noun_phrases = extract_noun_phrases(pos_tags)\n",
    "        \n",
    "        return torch.tensor(tokenisedids), torch.tensor(tagslist), noun_phrases\n",
    "    \n",
    "    def collate_fn(self , batch):\n",
    "        # batch is a list of tuples\n",
    "        # each tuple has 3 tensors , one for tokenisedids, one for tagslist, and one for noun_phrases\n",
    "        # we need to return a tensor of tokenisedids, a tensor of tagslist, and a list of lists for noun_phrases\n",
    "        tokenisedids = []\n",
    "        tagslist = []\n",
    "        noun_phrases = []\n",
    "        for tup in batch:\n",
    "            tokenisedids.append(torch.tensor(tup[0]))\n",
    "            tagslist.append(torch.tensor(tup[1]))\n",
    "            noun_phrases.append(tup[2])\n",
    "        \n",
    "        tokenisedids = torch.nn.utils.rnn.pad_sequence(tokenisedids , batch_first=True , padding_value=0) \n",
    "        tagslist = torch.nn.utils.rnn.pad_sequence(tagslist , batch_first=True , padding_value=0)\n",
    "\n",
    "        tokenisedids = tokenisedids.type(torch.LongTensor)\n",
    "        tagslist = tagslist.type(torch.LongTensor)\n",
    "        \n",
    "        return tokenisedids , tagslist, noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset('/Users/ashnadua/Desktop/INLP-project/scienceie2017_train/train2')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True , collate_fn=train_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gold_keywords(ann_file):\n",
    "    gold_keywords = set()\n",
    "    with open(ann_file, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('T'):\n",
    "                parts = line.split()\n",
    "                keyword = ' '.join(parts[4:])\n",
    "                gold_keywords.add(keyword.lower())\n",
    "    return gold_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(extracted_keywords, gold_keywords):\n",
    "    correctly_extracted = len(extracted_keywords.intersection(gold_keywords))\n",
    "    total_gold_keywords = len(gold_keywords)\n",
    "    accuracy = correctly_extracted / total_gold_keywords if total_gold_keywords > 0 else 0\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for S221266781400080X.txt: 0.0\n",
      "Accuracy for S2212671612000613.txt: 0.21428571428571427\n",
      "Accuracy for S0032386108010392.txt: 0.0\n",
      "Accuracy for S0370269304009232.txt: 0.2857142857142857\n",
      "Accuracy for S0003491615000433.txt: 0.05\n",
      "Accuracy for S0375960115005630.txt: 0.23529411764705882\n",
      "Accuracy for S0167931712003905.txt: 0.21428571428571427\n",
      "Accuracy for S0009261412012365.txt: 0.09375\n",
      "Accuracy for S0375960112002885.txt: 0.23529411764705882\n",
      "Accuracy for S0010938X15002085.txt: 0.45454545454545453\n",
      "Accuracy for S037596011300741X.txt: 0.16666666666666666\n",
      "Accuracy for S0927025612000249.txt: 0.07142857142857142\n",
      "Accuracy for S0370269304009347.txt: 0.2\n",
      "Accuracy for S0021999115001412.txt: 0.29411764705882354\n",
      "Accuracy for S1875952116300209.txt: 0.08333333333333333\n",
      "Accuracy for S0167931713004991.txt: 0.3333333333333333\n",
      "Accuracy for S2212667814001294.txt: 0.09090909090909091\n",
      "Accuracy for S0038092X15000559.txt: 0.21052631578947367\n",
      "Accuracy for S0165212511000874.txt: 0.1111111111111111\n",
      "Accuracy for S0370269304009025.txt: 0.0\n",
      "Accuracy for S0165212511000862.txt: 0.15384615384615385\n",
      "Accuracy for S0370269304008305.txt: 0.1\n",
      "Accuracy for S0370269304007208.txt: 0.058823529411764705\n",
      "Accuracy for S0022311515301963.txt: 0.24242424242424243\n",
      "Accuracy for S0045782513000479.txt: 0.18181818181818182\n",
      "Accuracy for S0045782515002686.txt: 0.23529411764705882\n",
      "Accuracy for S0377025714001682.txt: 0.3333333333333333\n",
      "Accuracy for S0895611116300684.txt: 0.16666666666666666\n",
      "Accuracy for S0888613X16300767.txt: 0.16666666666666666\n",
      "Accuracy for S0021999114008523.txt: 0.2222222222222222\n",
      "Accuracy for S1524070312000380.txt: 0.125\n",
      "Accuracy for S0370269304009608.txt: 0.11764705882352941\n",
      "Accuracy for S0379711215000223.txt: 0.2\n",
      "Accuracy for S2352179114200032.txt: 0.13636363636363635\n",
      "Accuracy for S2212671612001692.txt: 0.0\n",
      "Accuracy for S016793171300244X.txt: 0.15384615384615385\n",
      "Accuracy for S0003491615001505.txt: 0.15384615384615385\n",
      "Accuracy for S0378381215301291.txt: 0.2\n",
      "Accuracy for S037026930400721X.txt: 0.15384615384615385\n",
      "Accuracy for S0370157312000105.txt: 0.18181818181818182\n",
      "Accuracy for S0022311515300477.txt: 0.3333333333333333\n",
      "Accuracy for S0370269304009220.txt: 0.16\n",
      "Accuracy for S2212671612001709.txt: 0.1111111111111111\n",
      "Accuracy for S0370269304009803.txt: 0.13043478260869565\n",
      "Accuracy for S0370269304007634.txt: 0.5\n",
      "Accuracy for S0927025614007137.txt: 0.14705882352941177\n",
      "Accuracy for S2212671612002375.txt: 0.058823529411764705\n",
      "Accuracy for S0022311515002391.txt: 0.2\n",
      "Accuracy for S092702561300760X.txt: 0.25925925925925924\n",
      "Accuracy for S2212667814001245.txt: 0.1\n",
      "Accuracy for S0167931714000203.txt: 0.05263157894736842\n",
      "Accuracy for S0167273813005298.txt: 0.3\n",
      "Accuracy for S0370269304009037.txt: 0.2916666666666667\n",
      "Accuracy for S2212671612001291.txt: 0.15789473684210525\n",
      "Accuracy for S0377025713001031.txt: 0.42857142857142855\n",
      "Accuracy for S0009261412006513.txt: 0.30434782608695654\n",
      "Accuracy for S0038092X14004770.txt: 0.3333333333333333\n",
      "Accuracy for S0370269304006070.txt: 0.1875\n",
      "Accuracy for S0021999114002587.txt: 0.0\n",
      "Accuracy for S2212671612001497.txt: 0.26666666666666666\n",
      "Accuracy for S0370269304009141.txt: 0.13636363636363635\n",
      "Accuracy for S0168874X1630049X.txt: 0.2857142857142857\n",
      "Accuracy for S2212667814000987.txt: 0.0\n",
      "Accuracy for S2212667814001440.txt: 0.3684210526315789\n",
      "Accuracy for S2212667814000951.txt: 0.0\n",
      "Accuracy for S2212667812000822.txt: 0.15384615384615385\n",
      "Accuracy for S0167931713005042.txt: 0.08\n",
      "Accuracy for S0370269304008706.txt: 0.0\n",
      "Accuracy for S1361841516300822.txt: 0.2727272727272727\n",
      "Accuracy for S0377025714002213.txt: 0.3125\n",
      "Accuracy for S0375960113004908.txt: 0.18518518518518517\n",
      "Accuracy for S0038092X15001681.txt: 0.07692307692307693\n",
      "Accuracy for S0010938X14000420.txt: 0.4444444444444444\n",
      "Accuracy for S0003491615001955.txt: 0.21428571428571427\n",
      "Accuracy for S0032386110001667.txt: 0.3\n",
      "Accuracy for S2212671612001618.txt: 0.0\n",
      "Accuracy for S0168365913004975.txt: 0.65\n",
      "Accuracy for S0888327016302333.txt: 0.3125\n",
      "Accuracy for S0032386109010386.txt: 0.3235294117647059\n",
      "Accuracy for S2212671612000704.txt: 0.2777777777777778\n",
      "Accuracy for S0168365913002848.txt: 0.09090909090909091\n",
      "Accuracy for S2212667814001397.txt: 0.08333333333333333\n",
      "Accuracy for S2212667813000774.txt: 0.1111111111111111\n",
      "Accuracy for S074756321630348X.txt: 0.2222222222222222\n",
      "Accuracy for S2212671612002338.txt: 0.23809523809523808\n",
      "Accuracy for S0098300412001793.txt: 0.0\n",
      "Accuracy for S0098300413002951.txt: 0.1111111111111111\n",
      "Accuracy for S0009261412013838.txt: 0.15384615384615385\n",
      "Accuracy for S0022311515303640.txt: 0.24\n",
      "Accuracy for S0167273814004408.txt: 0.16666666666666666\n",
      "Accuracy for S0377025715000993.txt: 0.09090909090909091\n",
      "Accuracy for S0370157314001318.txt: 0.1875\n",
      "Accuracy for S2212667814001208.txt: 0.05\n",
      "Accuracy for S1364815216303541.txt: 0.07142857142857142\n",
      "Accuracy for S0254058415304235.txt: 0.16129032258064516\n",
      "Accuracy for S2212671612000698.txt: 0.23809523809523808\n",
      "Accuracy for S0167273813006735.txt: 0.10714285714285714\n",
      "Accuracy for S0370269304006161.txt: 0.125\n",
      "Accuracy for S0022311515301069.txt: 0.4375\n",
      "Accuracy for S0045782513000546.txt: 0.11764705882352941\n",
      "Accuracy for S0045782512003428.txt: 0.05555555555555555\n",
      "Accuracy for S0370269304007257.txt: 0.2777777777777778\n",
      "Accuracy for S0022311513011951.txt: 0.3\n",
      "Accuracy for S0165212515000931.txt: 0.2727272727272727\n",
      "Accuracy for S2212667813000762.txt: 0.21428571428571427\n",
      "Accuracy for S004578251400334X.txt: 0.2857142857142857\n",
      "Accuracy for S0045782515002418.txt: 0.2727272727272727\n",
      "Accuracy for S0038092X14000942.txt: 0.2\n",
      "Accuracy for S221450951400031X.txt: 0.21428571428571427\n",
      "Accuracy for S0021999115000546.txt: 0.2\n",
      "Accuracy for S0370269304009657.txt: 0.19047619047619047\n",
      "Accuracy for S0032386109001712.txt: 0.2608695652173913\n",
      "Accuracy for S0166218X14003011.txt: 0.2\n",
      "Accuracy for S0167273815004130.txt: 0.2962962962962963\n",
      "Accuracy for S037026930400680X.txt: 0.14285714285714285\n",
      "Accuracy for S0957417416303773.txt: 0.0\n",
      "Accuracy for S0370269304009086.txt: 0.06060606060606061\n",
      "Accuracy for S2214509515300103.txt: 0.375\n",
      "Accuracy for S0022311514008691.txt: 0.25806451612903225\n",
      "Accuracy for S0045782513001473.txt: 0.3333333333333333\n",
      "Accuracy for S088523081530036X.txt: 0.0\n",
      "Accuracy for S0021999113005603.txt: 0.2\n",
      "Accuracy for S0377025714000317.txt: 0.14285714285714285\n",
      "Accuracy for S2212667812000937.txt: 0.0\n",
      "Accuracy for S0045782514004812.txt: 0.0\n",
      "Accuracy for S2212667812000664.txt: 0.08333333333333333\n",
      "Accuracy for S0010938X13002187.txt: 0.09090909090909091\n",
      "Accuracy for S0963869514000863.txt: 0.35714285714285715\n",
      "Accuracy for S0370269304007695.txt: 0.20588235294117646\n",
      "Accuracy for S0029549314001551.txt: 0.30434782608695654\n",
      "Accuracy for S2212671612000716.txt: 0.23529411764705882\n",
      "Accuracy for S2212667814000070.txt: 0.041666666666666664\n",
      "Accuracy for S0167931712002699.txt: 0.2\n",
      "Accuracy for S0021999115007238.txt: 0.46153846153846156\n",
      "Accuracy for S0370157309002877.txt: 0.09523809523809523\n",
      "Accuracy for S2212671612002302.txt: 0.3076923076923077\n",
      "Accuracy for S2212667812000895.txt: 0.2857142857142857\n",
      "Accuracy for S0010938X12001163.txt: 0.037037037037037035\n",
      "Accuracy for S0370269304008809.txt: 0.0\n",
      "Accuracy for S0010938X13005945.txt: 0.1875\n",
      "Accuracy for S0370269304009530.txt: 0.1111111111111111\n",
      "Accuracy for S2212667813001068.txt: 0.2\n",
      "Accuracy for S0022311515300830.txt: 0.17857142857142858\n",
      "Accuracy for S0378381215300674.txt: 0.2\n",
      "Accuracy for S0022311514006849.txt: 0.10526315789473684\n",
      "Accuracy for S0022311513001165.txt: 0.07142857142857142\n",
      "Accuracy for S0021999114008432.txt: 0.0\n",
      "Accuracy for S2212667813000610.txt: 0.14285714285714285\n",
      "Accuracy for S0045782513001448.txt: 0.2\n",
      "Accuracy for S0166218X1300348X.txt: 0.0\n",
      "Accuracy for S2212667814000884.txt: 0.4\n",
      "Accuracy for S221266781300018X.txt: 0.0\n",
      "Accuracy for S0031920113000708.txt: 0.23529411764705882\n",
      "Accuracy for S0370269304009268.txt: 0.1\n",
      "Accuracy for S0021961413004321.txt: 0.125\n",
      "Accuracy for S0010938X15300512.txt: 0.25\n",
      "Accuracy for S221267161200176X.txt: 0.11764705882352941\n",
      "Accuracy for S0167931714003347.txt: 0.3103448275862069\n",
      "Accuracy for S0032386114008428.txt: 0.16666666666666666\n",
      "Accuracy for S2212667812000883.txt: 0.0\n",
      "Accuracy for S0045782512002678.txt: 0.16666666666666666\n",
      "Accuracy for S0010938X12002508.txt: 0.13333333333333333\n",
      "Accuracy for S2212667814000264.txt: 0.3333333333333333\n",
      "Accuracy for S2352179114200056.txt: 0.21428571428571427\n",
      "Accuracy for S221450951530005X.txt: 0.175\n",
      "Accuracy for S0022311511010014.txt: 0.0\n",
      "Accuracy for S0009261413006738.txt: 0.16666666666666666\n",
      "Accuracy for S0167273811005091.txt: 0.0\n",
      "Accuracy for S0370269304009335.txt: 0.16666666666666666\n",
      "Accuracy for S0079642514000887.txt: 0.0\n",
      "Accuracy for S037026930400930X.txt: 0.09090909090909091\n",
      "Accuracy for S0010938X1530161X.txt: 0.16666666666666666\n",
      "Accuracy for S0254058414000662.txt: 0.08333333333333333\n",
      "Accuracy for S0021999115008256.txt: 0.375\n",
      "Accuracy for S0997754612001318.txt: 0.25\n",
      "Accuracy for S2212671612001783.txt: 0.25\n",
      "Accuracy for S0021999115003459.txt: 0.0\n",
      "Accuracy for S221266781400121X.txt: 0.4\n",
      "Accuracy for S0167931713004061.txt: 0.1388888888888889\n",
      "Accuracy for S0167931713002438.txt: 0.18181818181818182\n",
      "Accuracy for S0167931712002936.txt: 0.10714285714285714\n",
      "Accuracy for S2212671612000686.txt: 0.08333333333333333\n",
      "Accuracy for S0306437913000768.txt: 0.1111111111111111\n",
      "Accuracy for S1566253516300069.txt: 0.14285714285714285\n",
      "Accuracy for S0266352X16301550.txt: 0.0\n",
      "Accuracy for S221266781200007X.txt: 0.21052631578947367\n",
      "Accuracy for S0370269304008998.txt: 0.13636363636363635\n",
      "Accuracy for S0167273814004548.txt: 0.29411764705882354\n",
      "Accuracy for S0167931712003012.txt: 0.25\n",
      "Accuracy for S2212671612001163.txt: 0.26666666666666666\n",
      "Accuracy for S0009261415000974.txt: 0.14285714285714285\n",
      "Accuracy for S0736585316300661.txt: 0.25\n",
      "Accuracy for S0045782515001899.txt: 0.0\n",
      "Accuracy for S2212667814001348.txt: 0.16666666666666666\n",
      "Accuracy for S0021999115003939.txt: 0.16666666666666666\n",
      "Accuracy for S0021999114007876.txt: 0.0\n",
      "Accuracy for S2214657115000052.txt: 0.05555555555555555\n",
      "Accuracy for S2212667814001361.txt: 0.1875\n",
      "Accuracy for S0022311515002470.txt: 0.3181818181818182\n",
      "Accuracy for S0888327016300048.txt: 0.13043478260869565\n",
      "Accuracy for S0168365913008766.txt: 0.043478260869565216\n",
      "Accuracy for S000926141500651X.txt: 0.4166666666666667\n",
      "Accuracy for S0377221716301904.txt: 0.0\n",
      "Accuracy for S0022311514001640.txt: 0.5625\n",
      "Accuracy for S2212667814000690.txt: 0.07142857142857142\n",
      "Accuracy for S000926141301539X.txt: 0.07142857142857142\n",
      "Accuracy for S2212667812000536.txt: 0.0\n",
      "Accuracy for S0375960113004568.txt: 0.0\n",
      "Accuracy for S0021999113002362.txt: 0.29411764705882354\n",
      "Accuracy for S0038092X11004129.txt: 0.3333333333333333\n",
      "Accuracy for S0370269304008780.txt: 0.0625\n",
      "Accuracy for S2212667814000069.txt: 0.1111111111111111\n",
      "Accuracy for S0022311515002664.txt: 0.125\n",
      "Accuracy for S0377221716300984.txt: 0.2222222222222222\n",
      "Accuracy for S2212667814000732.txt: 0.09090909090909091\n",
      "Accuracy for S0370269304007129.txt: 0.21428571428571427\n",
      "Accuracy for S0370269304009104.txt: 0.23529411764705882\n",
      "Accuracy for S030193221400144X.txt: 0.23076923076923078\n",
      "Accuracy for S0378381215300297.txt: 0.0\n",
      "Accuracy for S0031920113001222.txt: 0.0\n",
      "Accuracy for S0098300413002185.txt: 0.1\n",
      "Accuracy for S2212671612000121.txt: 0.2222222222222222\n",
      "Accuracy for S221266781300083X.txt: 0.26666666666666666\n",
      "Accuracy for S025405841530136X.txt: 0.08333333333333333\n",
      "Accuracy for S0370269304009074.txt: 0.07142857142857142\n",
      "Accuracy for S0009261413011111.txt: 0.15384615384615385\n",
      "Accuracy for S2212667814000124.txt: 0.16666666666666666\n",
      "Accuracy for S0021999115004301.txt: 0.0\n",
      "Accuracy for S0142061516308079.txt: 0.5\n",
      "Accuracy for S0377221716304258.txt: 0.0\n",
      "Accuracy for S2212671612002120.txt: 0.18181818181818182\n",
      "Accuracy for S2212667814000045.txt: 0.3076923076923077\n",
      "Accuracy for S0045782512000266.txt: 0.11764705882352941\n",
      "Accuracy for S0370269304008974.txt: 0.15384615384615385\n",
      "Accuracy for S0167931711005120.txt: 0.0625\n",
      "Accuracy for S0370269304006756.txt: 0.0\n",
      "Accuracy for S002231151500032X.txt: 0.25\n",
      "Accuracy for S0167273812003025.txt: 0.14285714285714285\n",
      "Accuracy for S0377221716303873.txt: 0.21052631578947367\n",
      "Accuracy for S0045782515003680.txt: 0.043478260869565216\n",
      "Accuracy for S0377025714000135.txt: 0.2222222222222222\n",
      "Accuracy for S0370269304009049.txt: 0.0\n",
      "Accuracy for S2212667812000524.txt: 0.1111111111111111\n",
      "Accuracy for S092702561300267X.txt: 0.1\n",
      "Accuracy for S2212667814000331.txt: 0.15384615384615385\n",
      "Accuracy for S1566253516300252.txt: 0.23529411764705882\n",
      "Accuracy for S0370269304006768.txt: 0.15384615384615385\n",
      "Accuracy for S0301932214001499.txt: 0.2413793103448276\n",
      "Accuracy for S0370269304008792.txt: 0.25\n",
      "Accuracy for S0032386109007423.txt: 0.13043478260869565\n",
      "Accuracy for S0010938X15002954.txt: 0.18181818181818182\n",
      "Accuracy for S0009261409006666.txt: 0.09090909090909091\n",
      "Accuracy for S0370269304009116.txt: 0.0\n",
      "Accuracy for S1071581916300854.txt: 0.14285714285714285\n",
      "Accuracy for S0167931713006904.txt: 0.1\n",
      "Accuracy for S221267161200162X.txt: 0.05555555555555555\n",
      "Accuracy for S2212667814001166.txt: 0.07142857142857142\n",
      "Accuracy for S0957417416301786.txt: 0.21428571428571427\n",
      "Accuracy for S0045782512003234.txt: 0.0625\n",
      "Accuracy for S0045782511003823.txt: 0.16666666666666666\n",
      "Accuracy for S0010938X15301189.txt: 0.09090909090909091\n",
      "Accuracy for S0370269304009062.txt: 0.058823529411764705\n",
      "Accuracy for S0370269304007701.txt: 0.07142857142857142\n",
      "Accuracy for S2214657115000179.txt: 0.125\n",
      "Accuracy for S2212667814000380.txt: 0.25\n",
      "Accuracy for S0022311514000919.txt: 0.4\n",
      "Accuracy for S2212667812000032.txt: 0.0\n",
      "Accuracy for S0370269304008858.txt: 0.07142857142857142\n",
      "Accuracy for S0393044012000198.txt: 0.125\n",
      "Accuracy for S0022311515300295.txt: 0.13333333333333333\n",
      "Accuracy for S0022311514007119.txt: 0.15789473684210525\n",
      "Accuracy for S0165168416300603.txt: 0.07692307692307693\n",
      "Accuracy for S0168365913009036.txt: 0.1111111111111111\n",
      "Accuracy for S0370269304009165.txt: 0.16666666666666666\n",
      "Accuracy for S003238610900086X.txt: 0.3\n",
      "Accuracy for S221267161200217X.txt: 0.16666666666666666\n",
      "Accuracy for S2212667814001464.txt: 0.16666666666666666\n",
      "Accuracy for S0301932215002037.txt: 0.2222222222222222\n",
      "Accuracy for S2212667814000975.txt: 0.2857142857142857\n",
      "Accuracy for S2212667814000550.txt: 0.5\n",
      "Accuracy for S0370269304006082.txt: 0.0\n",
      "Accuracy for S0168365912006207.txt: 0.0\n",
      "Accuracy for S0375960113010839.txt: 0.25\n",
      "Accuracy for S0370269304007439.txt: 0.14814814814814814\n",
      "Accuracy for S0032386109006612.txt: 0.045454545454545456\n",
      "Accuracy for S0377025714001931.txt: 0.36363636363636365\n",
      "Accuracy for S0098300413002720.txt: 0.0\n",
      "Accuracy for S0021999113005652.txt: 0.5\n",
      "Accuracy for S0370269304007798.txt: 0.15384615384615385\n",
      "Accuracy for S0888613X16301062.txt: 0.06666666666666667\n",
      "Accuracy for S0301010415002256.txt: 0.16666666666666666\n",
      "Accuracy for S0370269304009979.txt: 0.2857142857142857\n",
      "Accuracy for S0375960115004120.txt: 0.4\n",
      "Accuracy for S0021999115008207.txt: 0.3333333333333333\n",
      "Accuracy for S0377025715000051.txt: 0.06666666666666667\n",
      "Accuracy for S0305054816300867.txt: 0.16666666666666666\n",
      "Accuracy for S0045782515001231.txt: 0.16666666666666666\n",
      "Accuracy for S2212667812000780.txt: 0.3333333333333333\n",
      "Accuracy for S2212667812000810.txt: 0.4\n",
      "Accuracy for S0301010414003115.txt: 0.1\n",
      "Accuracy for S0021999114007396.txt: 0.09090909090909091\n",
      "Accuracy for S221266781400149X.txt: 0.19047619047619047\n",
      "Accuracy for S0021999113005718.txt: 0.25\n",
      "Accuracy for S0168365913003295.txt: 0.11538461538461539\n",
      "Accuracy for S0375960113006725.txt: 0.0\n",
      "Accuracy for S0032386110004039.txt: 0.12\n",
      "Accuracy for S2212671612002351.txt: 0.4666666666666667\n",
      "Accuracy for S0370269304009359.txt: 0.2962962962962963\n",
      "Accuracy for S0370269304009013.txt: 0.47368421052631576\n",
      "Accuracy for S0045782514001492.txt: 0.13333333333333333\n",
      "Accuracy for S0167931713002487.txt: 0.046511627906976744\n",
      "Accuracy for S003238610801080X.txt: 0.06666666666666667\n",
      "Accuracy for S1570870516301822.txt: 0.0\n",
      "Accuracy for S0032386109005485.txt: 0.1875\n",
      "Accuracy for S221267161200220X.txt: 0.25\n",
      "Accuracy for S2212667812000949.txt: 0.14285714285714285\n",
      "Accuracy for S0370269304008731.txt: 0.15384615384615385\n",
      "Accuracy for S0370269304006720.txt: 0.3333333333333333\n",
      "Accuracy for S0749603615302184.txt: 0.0\n",
      "Accuracy for S0039602899010869.txt: 0.18181818181818182\n",
      "Accuracy for S0010938X1500195X.txt: 0.3\n",
      "Accuracy for S0370269304009177.txt: 0.25\n",
      "Accuracy for S2212667814001488.txt: 0.1111111111111111\n",
      "Accuracy for S0021999113003422.txt: 0.0\n",
      "Accuracy for S0377221716301357.txt: 0.1\n",
      "Accuracy for S0045782514000607.txt: 0.23529411764705882\n",
      "Accuracy for S1361841516300342.txt: 0.1111111111111111\n",
      "Accuracy for S0370269304009189.txt: 0.30303030303030304\n",
      "Accuracy for S2212667814001476.txt: 0.1\n",
      "Accuracy for S2212671612002181.txt: 0.29411764705882354\n",
      "Accuracy for S0045782512002599.txt: 0.037037037037037035\n",
      "Accuracy for S0370269304007749.txt: 0.0\n",
      "Accuracy for S0022311514005480.txt: 0.2857142857142857\n",
      "Accuracy for S2212671612000637.txt: 0.3333333333333333\n",
      "Accuracy for S0009261415002730.txt: 0.1875\n",
      "Accuracy for S2212667812000792.txt: 0.375\n",
      "Accuracy for S0377221716302259.txt: 0.08333333333333333\n",
      "Accuracy for S0167931714004456.txt: 0.19047619047619047\n",
      "Accuracy for S0029549314002970.txt: 0.26666666666666666\n",
      "Accuracy for S0254058415001212.txt: 0.22727272727272727\n",
      "Accuracy for S2212667814000756.txt: 0.2222222222222222\n",
      "Accuracy for S0885230816300043.txt: 0.1\n",
      "Accuracy for S0957417416302561.txt: 0.25\n",
      "Accuracy for S004578251300176X.txt: 0.45454545454545453\n",
      "Accuracy for S0021999113006955.txt: 0.4666666666666667\n",
      "Accuracy for S0032386109004996.txt: 0.4\n",
      "Accuracy for S0379711213001653.txt: 0.125\n",
      "Accuracy for S0032386109007290.txt: 0.21428571428571427\n",
      "Accuracy for S0301010414003516.txt: 0.25\n",
      "Accuracy for S2214657115000155.txt: 0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "data_dir = '/Users/ashnadua/Desktop/INLP-project/scienceie2017_train/train2'\n",
    "\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".txt\"):\n",
    "        txt_path = os.path.join(data_dir, file)\n",
    "        ann_path = os.path.join(data_dir, file[:-3] + \"ann\")\n",
    "\n",
    "        with open(txt_path, 'r') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        tokens = word_tokenize(text)\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "        noun_phrases = extract_noun_phrases(pos_tags)\n",
    "        noun_phrases = set(noun_phrases)  # Convert to set\n",
    "\n",
    "        gold_keywords = load_gold_keywords(ann_path)\n",
    "\n",
    "        accuracy = calculate_accuracy(noun_phrases, gold_keywords)\n",
    "        print(f\"Accuracy for {os.path.basename(txt_path)}: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oxidation', 'behavior', 'barrier', 'use', 'demand', 'service', 'temperature', 'temperature', 'limit', 'study', 'role', 'composition', 'oxidation', 'behavior', 'attempt', 'limitation', 'alloys', 'production', 'oxidation', 'resistance', 'development', 'pre-oxidation', 'oxidation', 'behavior', 'oxidation', 'rate', 'law', 'depth', 'oxygen', 'ingress', 'thickness', 'number', 'oxidation', 'condition', 'range', 'literature', ']', 'the demand', 'the service', 'these', 'the role', 'that composition', 'the oxidation', 'the attempt', 'this limitation', 'the production', 'the oxidation', 'the literature', 'poor oxidation', 'major barrier', 'ti-based', 'structural', 'typical temperature', 'careful study', 'ti-based', 'ti-based alloys', 'scale thickness', 'limited number', 'certain oxidation', 'compositional range', 'numerous', 'expected', 'the major barrier', 'the typical temperature', 'a limited number', 'a certain oxidation', 'the expected', 'production of', 'development of', 'depth of oxygen', 'number of']\n"
     ]
    }
   ],
   "source": [
    "text = \"Poor oxidation behavior is the major barrier to the increased use of Ti-based alloys in high-temperature structural applications. The demand to increase the service temperature of these alloys beyond 550°C (the typical temperature limit) requires careful study to understand the role that composition has on the oxidation behavior of Ti-based alloys [1–3]. The attempt to overcome this limitation in Ti-based alloys has led to the production of alloys with substantially improved oxidation resistance such as β-21S and also development of coatings and pre-oxidation techniques [1,4–6]. While it is tempting to extrapolate the oxidation behavior (e.g. oxidation rate law, depth of oxygen ingress and scale thickness) observed for a limited number of compositions under a certain oxidation condition to a broader compositional range, there are numerous examples in the literature where deviations from the expected relations are observed [7,8].\"\n",
    "text = text.lower()\n",
    "tokens = nltk.word_tokenize(text)\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "noun_phrases = extract_noun_phrases(pos_tags)\n",
    "print(noun_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_phrases = set(noun_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4\n"
     ]
    }
   ],
   "source": [
    "ann_file = '/Users/ashnadua/Desktop/INLP-project/scienceie2017_train/train2/S0010938X1500195X.ann'  # Path to your annotation file\n",
    "gold_keywords = load_gold_keywords(ann_file)\n",
    "\n",
    "accuracy = calculate_accuracy(noun_phrases, gold_keywords)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(20):\n",
    "#     tokenisedids, tagslist, noun_phrases = train_dataset[i]\n",
    "#     print(f\"Sample {i+1}:\")\n",
    "#     print(\"Tokenized Text:\", tokenisedids)\n",
    "#     print(\"Tags List:\", tagslist)\n",
    "#     print(\"Noun Phrases:\", noun_phrases)\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "\n",
    "# def extract_noun_phrases_spacy(text):\n",
    "#     nlp = spacy.load('en_core_web_sm')\n",
    "#     doc = nlp(text)\n",
    "#     noun_phrases = [chunk.text for chunk in doc.noun_chunks]\n",
    "#     return noun_phrases\n",
    "\n",
    "# # Example usage:\n",
    "# text = \"This is an example sentence with keywords like beautiful flowers and green grass.\"\n",
    "# noun_phrases_spacy = extract_noun_phrases_spacy(text)\n",
    "# print(noun_phrases_spacy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
